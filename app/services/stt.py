import whisper
import torch
import os
from dotenv import load_dotenv

load_dotenv()

# Load Whisper model once at startup
WHISPER_MODEL_NAME = os.getenv("WHISPER_MODEL", "tiny")

# ğŸ”’ Render Free: Always CPU
device = "cpu"

print(f"ğŸ™ï¸ [STT] Loading Whisper model: {WHISPER_MODEL_NAME} on {device}")
whisper_model = whisper.load_model(WHISPER_MODEL_NAME, device=device)
print("âœ… [STT] Whisper model loaded successfully")

async def transcribe_audio(audio_path: str, language: str = None) -> dict:
    '''
    Transcribe audio file to text using Whisper
    '''
    try:
        print("ğŸ§ [STT] Transcription process started...")
        print("ğŸ“‚ [STT] Audio file:", audio_path)

        # Map language codes to Whisper format
        language_map = {
            "hi": "hi",
            "ta": "ta",
            "te": "te",
            "bn": "bn",
            "mr": "mr",
            "gu": "gu",
            "pa": "pa",
            "kn": "kn",
            "ml": "ml",
        }

        whisper_lang = language_map.get(language, language) if language else None

        if whisper_lang:
            print(f"ğŸŒ [STT] Forcing language: {whisper_lang}")
        else:
            print("ğŸŒ [STT] Auto language detection enabled")

        # Transcribe (CPU safe)
        result = whisper_model.transcribe(
            audio_path,
            language=whisper_lang,
            fp16=False
        )

        text = result["text"].strip()
        detected_lang = result.get("language", "unknown")

        print("âœ… [STT] Transcription completed successfully!")
        print(f"ğŸ—£ï¸ [STT] Detected language: {detected_lang}")
        print("ğŸ“¢ [STT] FULL TRANSCRIBED TEXT:")
        print(text)
        print("==================================================")

        return {
            "text": text,
            "language": detected_lang
        }

    except Exception as e:
        print("âŒ [STT] Transcription Error:", e)
        raise Exception(f"Transcription error: {str(e)}")
